{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Face Recognition - Transfer Learning (MobileNetV2)\n",
    "## Untuk Final Project - Attendance System\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Platform: Kaggle Notebook\n",
    "\n",
    "**Cara setup di Kaggle:**\n",
    "1. Buka [kaggle.com](https://www.kaggle.com/) ‚Üí **New Notebook**\n",
    "2. Upload notebook ini atau copy-paste cell-nya\n",
    "3. **Upload dataset** sebagai Kaggle Dataset:\n",
    "   - Klik **\"Add Data\"** (sidebar kanan) ‚Üí **\"Upload\"** ‚Üí **\"New Dataset\"**\n",
    "   - Upload folder/zip dataset dengan struktur:\n",
    "     ```\n",
    "     dataset/\n",
    "     ‚îú‚îÄ‚îÄ Queensya/\n",
    "     ‚îÇ   ‚îú‚îÄ‚îÄ photo_001.jpg\n",
    "     ‚îÇ   ‚îú‚îÄ‚îÄ photo_002.jpg\n",
    "     ‚îÇ   ‚îî‚îÄ‚îÄ ... (20-50 foto)\n",
    "     ‚îú‚îÄ‚îÄ Danisw/\n",
    "     ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "     ‚îî‚îÄ‚îÄ Person3/\n",
    "         ‚îî‚îÄ‚îÄ ...\n",
    "     ```\n",
    "   - Beri nama dataset, misal: `face-dataset`\n",
    "4. **Settings** ‚Üí Aktifkan **GPU** (Accelerator: GPU T4 x2 atau P100)\n",
    "5. Run semua cell dari atas ke bawah!\n",
    "\n",
    "### üìÅ Path di Kaggle:\n",
    "| Lokasi | Path |\n",
    "|--------|------|\n",
    "| Input (dataset) | `/kaggle/input/face-dataset/dataset/` |\n",
    "| Output (model) | `/kaggle/working/` |\n",
    "\n",
    "### üéØ Output:\n",
    "- `keras_model.h5` - Model trained (kompatibel dengan Teachable Machine format)\n",
    "- `labels.txt` - Daftar nama orang\n",
    "- Copy kedua file ke `minggu-8-final-project/project/models/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Platform: Kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÅ Step 2: Cari & Load Dataset\n",
    "\n",
    "Kaggle menyimpan dataset yang kamu upload di `/kaggle/input/`.\n",
    "\n",
    "**Pastikan kamu sudah:**\n",
    "1. Klik **\"Add Data\"** di sidebar kanan\n",
    "2. Upload dataset dengan folder per orang\n",
    "3. Cell di bawah akan otomatis menemukan folder dataset-nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AUTO-DETECT DATASET PATH\n",
    "# ============================================\n",
    "\n",
    "KAGGLE_INPUT = Path('/kaggle/input')\n",
    "DATASET_PATH = None\n",
    "\n",
    "print(\"üîç Mencari dataset di /kaggle/input/...\\n\")\n",
    "\n",
    "# Cari folder yang berisi subfolder (orang-orang)\n",
    "for dataset_dir in sorted(KAGGLE_INPUT.iterdir()):\n",
    "    if not dataset_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    # Cek semua subfolder\n",
    "    for sub in sorted(dataset_dir.rglob('*')):\n",
    "        if sub.is_dir():\n",
    "            # Cek apakah folder ini berisi gambar\n",
    "            images = list(sub.glob('*.jpg')) + list(sub.glob('*.jpeg')) + list(sub.glob('*.png'))\n",
    "            if len(images) > 0:\n",
    "                # Parent folder dari folder orang = dataset root\n",
    "                candidate = sub.parent\n",
    "                # Pastikan ada minimal 2 subfolder (minimal 2 orang)\n",
    "                person_folders = [d for d in candidate.iterdir() if d.is_dir()]\n",
    "                if len(person_folders) >= 2:\n",
    "                    DATASET_PATH = str(candidate)\n",
    "                    break\n",
    "    if DATASET_PATH:\n",
    "        break\n",
    "\n",
    "if DATASET_PATH is None:\n",
    "    print(\"‚ùå Dataset tidak ditemukan!\")\n",
    "    print(\"\\nüí° Pastikan:\")\n",
    "    print(\"   1. Klik 'Add Data' di sidebar kanan\")\n",
    "    print(\"   2. Upload dataset dengan struktur folder per orang\")\n",
    "    print(\"   3. Setiap folder berisi foto .jpg/.png\")\n",
    "    print(\"\\nüìÅ Isi /kaggle/input/:\")\n",
    "    for p in KAGGLE_INPUT.rglob('*'):\n",
    "        level = len(p.relative_to(KAGGLE_INPUT).parts)\n",
    "        if level <= 3:\n",
    "            indent = '  ' * level\n",
    "            print(f\"{indent}{p.name}{'/' if p.is_dir() else ''}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset ditemukan: {DATASET_PATH}\")\n",
    "    print(f\"\\nüìÇ Orang yang ditemukan:\")\n",
    "    total_images = 0\n",
    "    for person_dir in sorted(Path(DATASET_PATH).iterdir()):\n",
    "        if person_dir.is_dir():\n",
    "            imgs = list(person_dir.glob('*.jpg')) + list(person_dir.glob('*.jpeg')) + list(person_dir.glob('*.png'))\n",
    "            total_images += len(imgs)\n",
    "            print(f\"   üë§ {person_dir.name}: {len(imgs)} foto\")\n",
    "    print(f\"\\nüìä Total: {total_images} foto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è Step 3: Configuration\n",
    "\n",
    "Sesuaikan parameter di bawah jika perlu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION - Sesuaikan jika perlu\n",
    "# ============================================\n",
    "\n",
    "IMG_SIZE = 224              # Ukuran input (sama dengan Teachable Machine)\n",
    "BATCH_SIZE = 32             # Batch size\n",
    "EPOCHS = 50                 # Max epochs (early stopping akan stop lebih awal)\n",
    "VALIDATION_SPLIT = 0.2     # 20% untuk validation\n",
    "LEARNING_RATE = 0.0001     # Learning rate awal\n",
    "\n",
    "# Output path (Kaggle working directory)\n",
    "OUTPUT_DIR = '/kaggle/working'\n",
    "\n",
    "print(\"‚úÖ Configuration:\")\n",
    "print(f\"   Image size    : {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Batch size    : {BATCH_SIZE}\")\n",
    "print(f\"   Max epochs    : {EPOCHS}\")\n",
    "print(f\"   Val split     : {VALIDATION_SPLIT}\")\n",
    "print(f\"   Learning rate : {LEARNING_RATE}\")\n",
    "print(f\"   Output dir    : {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Step 4: Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation untuk training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.15,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation hanya rescale, tanpa augmentation\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded!\")\n",
    "print(f\"   Training   : {train_generator.samples} samples\")\n",
    "print(f\"   Validation : {val_generator.samples} samples\")\n",
    "print(f\"   Classes ({num_classes}): {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images dengan augmentation\n",
    "plt.figure(figsize=(12, 12))\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "for i in range(min(9, len(images))):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    label_idx = np.argmax(labels[i])\n",
    "    plt.title(f\"{class_names[label_idx]}\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('üì∑ Sample Training Images (with Augmentation)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Step 5: Build Model (MobileNetV2 Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained MobileNetV2 (tanpa top layer)\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze base model (jangan train dulu)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build classification head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model built!\")\n",
    "print(f\"   Base: MobileNetV2 (ImageNet pretrained)\")\n",
    "print(f\"   Output classes: {num_classes}\")\n",
    "print(f\"   Total params: {model.count_params():,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèãÔ∏è Step 6: Training (Phase 1 - Train Head Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, 'best_model_phase1.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"üèãÔ∏è Phase 1: Training classification head...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Phase 1 complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî• Step 7: Fine-tuning (Phase 2 - Unfreeze Top Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze 30 layer terakhir dari MobileNetV2\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile dengan learning rate lebih kecil\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE / 10),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=4,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, 'best_model_phase2.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"üî• Phase 2: Fine-tuning...\\n\")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks_ft,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà Step 8: Evaluate & Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Phase 1 Train', color='blue')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Phase 1 Val', color='blue', linestyle='--')\n",
    "if history_fine:\n",
    "    offset = len(history.history['accuracy'])\n",
    "    epochs_ft = range(offset, offset + len(history_fine.history['accuracy']))\n",
    "    axes[0].plot(epochs_ft, history_fine.history['accuracy'], label='Phase 2 Train', color='red')\n",
    "    axes[0].plot(epochs_ft, history_fine.history['val_accuracy'], label='Phase 2 Val', color='red', linestyle='--')\n",
    "axes[0].set_title('Accuracy', fontsize=14)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Phase 1 Train', color='blue')\n",
    "axes[1].plot(history.history['val_loss'], label='Phase 1 Val', color='blue', linestyle='--')\n",
    "if history_fine:\n",
    "    axes[1].plot(epochs_ft, history_fine.history['loss'], label='Phase 2 Train', color='red')\n",
    "    axes[1].plot(epochs_ft, history_fine.history['val_loss'], label='Phase 2 Val', color='red', linestyle='--')\n",
    "axes[1].set_title('Loss', fontsize=14)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('üìà Training History', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final score\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"\\nüìä Final Validation Accuracy: {val_accuracy:.2%}\")\n",
    "print(f\"üìä Final Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix & Classification Report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "val_generator.reset()\n",
    "predictions = model.predict(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = val_generator.classes\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Annotate cells\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center',\n",
    "                 color='white' if cm[i, j] > cm.max()/2 else 'black', fontsize=14)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ Step 9: Export Model (Teachable Machine Format)\n",
    "\n",
    "Output disimpan di `/kaggle/working/` ‚Üí otomatis muncul di tab **Output** Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SAVE ke /kaggle/working/ (auto-download)\n",
    "# ============================================\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(OUTPUT_DIR, 'keras_model.h5')\n",
    "model.save(model_path)\n",
    "print(f\"‚úÖ Model saved: {model_path}\")\n",
    "\n",
    "# Save labels.txt (format Teachable Machine)\n",
    "labels_path = os.path.join(OUTPUT_DIR, 'labels.txt')\n",
    "with open(labels_path, 'w') as f:\n",
    "    for idx, name in enumerate(class_names):\n",
    "        f.write(f\"{idx} {name}\\n\")\n",
    "print(f\"‚úÖ Labels saved: {labels_path}\")\n",
    "\n",
    "# Show labels\n",
    "print(f\"\\nüìã labels.txt:\")\n",
    "with open(labels_path, 'r') as f:\n",
    "    print(f.read())\n",
    "\n",
    "# File sizes\n",
    "model_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "print(f\"üì¶ Model size: {model_size:.1f} MB\")\n",
    "print(f\"üìä Accuracy: {val_accuracy:.2%}\")\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"üì• DOWNLOAD:\")\n",
    "print(f\"   Klik tab 'Output' di sidebar kanan Kaggle\")\n",
    "print(f\"   Download keras_model.h5 dan labels.txt\")\n",
    "print(f\"   Copy ke: minggu-8-final-project/project/models/\")\n",
    "print(f\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß™ Step 10: Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction pada beberapa gambar\n",
    "from PIL import Image\n",
    "\n",
    "print(\"üß™ Testing model...\\n\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for class_folder in sorted(os.listdir(DATASET_PATH)):\n",
    "    class_path = os.path.join(DATASET_PATH, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    \n",
    "    images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    test_images = images[:3]  # Test 3 foto per orang\n",
    "    \n",
    "    for img_name in test_images:\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = Image.open(img_path).resize((IMG_SIZE, IMG_SIZE))\n",
    "        img_array = np.array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        preds = model.predict(img_array, verbose=0)\n",
    "        pred_idx = np.argmax(preds[0])\n",
    "        pred_name = class_names[pred_idx]\n",
    "        confidence = preds[0][pred_idx]\n",
    "        \n",
    "        is_correct = pred_name == class_folder\n",
    "        status = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        print(f\"{status} True: {class_folder:15} ‚Üí Predicted: {pred_name:15} ({confidence:.1%})\")\n",
    "\n",
    "print(f\"\\nüìä Test Accuracy: {correct}/{total} = {correct/total:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Selesai!\n",
    "\n",
    "### Cara download dari Kaggle:\n",
    "1. Lihat sidebar kanan ‚Üí tab **\"Output\"**\n",
    "2. Download `keras_model.h5` dan `labels.txt`\n",
    "3. Copy ke folder project:\n",
    "   ```\n",
    "   minggu-8-final-project/project/models/\n",
    "   ‚îú‚îÄ‚îÄ keras_model.h5    ‚Üê copy ke sini\n",
    "   ‚îî‚îÄ‚îÄ labels.txt        ‚Üê copy ke sini\n",
    "   ```\n",
    "4. Jalankan aplikasi:\n",
    "   ```bash\n",
    "   cd minggu-8-final-project/project\n",
    "   python main_app.py\n",
    "   ```\n",
    "\n",
    "### Tips:\n",
    "- Kalau akurasi rendah, tambah lebih banyak foto per orang\n",
    "- Pastikan foto bervariasi (angle, ekspresi, cahaya)\n",
    "- Model ini **kompatibel** dengan format Teachable Machine\n",
    "- File output otomatis tersimpan di Kaggle dan bisa didownload kapan saja"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
